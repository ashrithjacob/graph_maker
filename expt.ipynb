{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from graph_maker import GraphMaker, Ontology, GroqClient, OpenAIClient\n",
    "from graph_maker import Document\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from graph_maker import Document\n",
    "import pandas as pd\n",
    "import pyvis\n",
    "from pyvis.network import Network\n",
    "from falkordb import FalkorDB\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "class ProcessConversation:\n",
    "    CORESOLUTION_SYSTEM_PROMPT = \"\"\"\n",
    "                                    You are a coresolution resolver, which is to say you replace all pronouns referencing an object\n",
    "                                    with it's proper noun based on the context.\n",
    "                                    Ensure to also infer who 'I' refers to based on the context and replace all Is witht the proper noun.\n",
    "                                    Example input:\n",
    "                                    `Elon Musk was born in South Africa. There, he briefly attended classes at the University of Pretoria`\n",
    "\n",
    "                                    Example output:\n",
    "                                    `Elon Musk was born in South Africa. In South Africa, Elon briefly attended classes at the University of Pretoria`'\n",
    "\n",
    "                                    Keep the same structure of the text as passed to you in the text body.\n",
    "                                \"\"\"\n",
    "\n",
    "    #extract text from file\n",
    "    @classmethod\n",
    "    def _text_from_file(cls, file):\n",
    "        with open(file) as f:\n",
    "            text = f.read()\n",
    "        return text\n",
    "\n",
    "    @classmethod\n",
    "    def create_outfile_path(cls, infile_file_path):\n",
    "        return os.path.splitext(infile_file_path)[0] + \"_renamed.txt\"\n",
    "    \n",
    "    # split text into sentences\n",
    "    @classmethod\n",
    "    def sentence_splitter(cls, text):\n",
    "        sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "        return sentences\n",
    "\n",
    "    #create Document format\n",
    "    @classmethod\n",
    "    def create_docs(cls, sentences):\n",
    "        docs = [Document(text=sentence[\"text\"], metadata={\"num\": str(idx), \"speaker\":sentence[\"speaker\"]}) for (idx, sentence) in enumerate(sentences)]\n",
    "        return docs\n",
    "\n",
    "    # run coreference resolution\n",
    "    @classmethod\n",
    "    def coreference_resolution(cls, text):\n",
    "        #TODO: entire text is dumped for the time being, need to split it into chunks if it exceeds the limit\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": cls.CORESOLUTION_SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": f\"{text}\"},\n",
    "        ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    @classmethod\n",
    "    # replace dummy mappings with actual names in each line\n",
    "    def _replace_speaker_with_mapping(cls, line, speaker_mapping):\n",
    "        for key, value in speaker_mapping.items():\n",
    "            if key in line:\n",
    "                line = line.replace(key, value)\n",
    "        return line\n",
    "    \n",
    "    @classmethod\n",
    "    #store texts and speakers in a list of dictionaries\n",
    "    def _extract_speaker_and_text(cls, sentences):\n",
    "        speaker_text_store = []\n",
    "        for input_string in sentences:\n",
    "            print(input_string)\n",
    "            speaker_match = re.search(r'speaker:(.*?)\\|', input_string).group(1).strip()\n",
    "            text_match = re.search(r'text:(.*)', input_string).group(1).strip()\n",
    "            speaker_text_store.append({\"text\":text_match, \"speaker\":speaker_match})\n",
    "        return speaker_text_store\n",
    "    \n",
    "    @classmethod\n",
    "    #clump sentences together based on speaker and chunk limit, whichever comes first\n",
    "    def clump_sentences(cls, sentences, chunk_limit):\n",
    "        current_speaker = sentences[0][\"speaker\"]\n",
    "        text = \"\"\n",
    "        chunk_number = 0\n",
    "        clumped_sentences = []\n",
    "        for sentence in sentences:\n",
    "            if sentence[\"speaker\"] == current_speaker and chunk_number < chunk_limit:\n",
    "                text += sentence[\"text\"]\n",
    "                chunk_number += 1\n",
    "            elif sentence[\"speaker\"] != current_speaker or chunk_number >= chunk_limit:\n",
    "                clumped_sentences.append({\"text\": text, \"speaker\":current_speaker})\n",
    "                current_speaker = sentence[\"speaker\"]\n",
    "                text = sentence[\"text\"]\n",
    "                chunk_number = 1\n",
    "        else:\n",
    "            clumped_sentences.append({\"text\": text, \"speaker\":current_speaker})\n",
    "        return clumped_sentences\n",
    "\n",
    "    @classmethod\n",
    "    def process_sentences(cls, sentences, chunk_limit):\n",
    "        speaker_text_store = cls._extract_speaker_and_text(sentences)\n",
    "        sentences_clumped = cls.clump_sentences(speaker_text_store, chunk_limit)\n",
    "        return sentences_clumped\n",
    "\n",
    "    @classmethod\n",
    "    #write conversation with correct speaker names to file\n",
    "    def write_conversation_to_file(cls):\n",
    "        # Replace speaker in conversation:\n",
    "        if not os.path.exists(cls.outfile_file_path):\n",
    "            with open(cls.infile_file_path, 'r') as infile, open(cls.outfile_file_path, 'w') as outfile:\n",
    "                # Read the lines from the input file\n",
    "                for line in infile.readlines():\n",
    "                    processed_line = cls._replace_speaker_with_mapping(line)\n",
    "                    outfile.write(processed_line)\n",
    "\n",
    "    @classmethod\n",
    "    #run the entire preprocessing pipeline\n",
    "    def run(cls, infile_file_path):\n",
    "        cls.infile_file_path = infile_file_path\n",
    "        cls.outfile_file_path = cls.create_outfile_path(infile_file_path)\n",
    "        cls.write_conversation_to_file()\n",
    "        text = cls._text_from_file(cls.outfile_file_path)\n",
    "        coresolved_text = cls.coreference_resolution(text)\n",
    "        sentences = cls.sentence_splitter(coresolved_text)\n",
    "        sentences_processed = cls.process_sentences(sentences, chunk_limit=3)\n",
    "        docs = cls.create_docs(sentences_processed)\n",
    "        return docs\n",
    "\n",
    "    @classmethod    \n",
    "    def line_generator(cls, file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            for line in file:\n",
    "                yield line.strip()\n",
    "        \n",
    "    @classmethod\n",
    "    def aggregate_text(cls, text):\n",
    "        pattern = r'text:\\s*(.*?)(?=\\n|$)'\n",
    "        matches = re.findall(pattern, text)\n",
    "        all_text = ' '.join(matches) \n",
    "        return all_text       \n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def create_docs(cls, infile_file_path, speaker_mapping):\n",
    "        text =\"\"\n",
    "        line_gen = cls.line_generator(infile_file_path)\n",
    "        for line in line_gen:\n",
    "            text += str(cls._replace_speaker_with_mapping(line, speaker_mapping)) + \"\\n\"\n",
    "        coresolution_resolved_text = cls.coreference_resolution(text)\n",
    "        all_text = cls.aggregate_text(coresolution_resolved_text)\n",
    "        print(all_text)\n",
    "        return [Document(text=all_text, metadata={\"num\": \"1\"})]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateGraph:\n",
    "    GRAPH_CLEANER_PROMPT = \"\"\"\n",
    "                            You are an expert at generating open cypher queries.\n",
    "                            You are provided with a list of cypher queries for creation of new nodes and edges.\n",
    "                            Your duty is as follows:\n",
    "                            - Make the relationships between the nodes simpler and less verbose without losing the meaning.\n",
    "                            - Do not miss out any nuances or details that are present in the relationship part of the query.\n",
    "                            \n",
    "                            YOU WILL BE PENALIZED FOR CHANGING THE MEANING IN ANY WAY.\n",
    "                            DO NOT ADD OR REMOVE ANY NODES OR RELATIONSHIPS.\n",
    "\n",
    "                            Ensure to use metadata in the relationship elements to capture any details that cannot be captured otherwise\n",
    "\n",
    "                            Examples:\n",
    "                            CREATE (charlie:Person:Actor {name: 'Charlie Sheen'})-[:ACTED_IN {role: 'Bud Fox'}]->(wallStreet:Movie {title: 'Wall Street'})<-[:DIRECTED]-(oliver:Person:Director {name: 'Oliver Stone'})\n",
    "\n",
    "                            Notice how in the relationship 'ACTED_IN' the role of 'Bud fox' is present.\n",
    "                            \"\"\"\n",
    "    EXAMPLE_PROMPT = \"\"\"\n",
    "                        CREATE\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_bought_a_d6_bulldozer]->(:Object {name:\"d6 bulldozer\"}),\n",
    "                        (:Object {name:\"d6 bulldozer\"})-[:The_d6_bulldozer_is_described_as_a_big_bulldozer]->(:Miscellanous {name:\"big bulldozer\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_got_the_bulldozer_for_five_thousand_dollars]->(:Object {name:\"d6 bulldozer\"}),\n",
    "                        (:Object {name:\"d6 bulldozer\"})-[:The_d6_bulldozer_is_specifically_a_1955_caterpillar_d6_bulldozer]->(:Miscellanous {name:\"1955 caterpillar d6 bulldozer\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_spent_an_entire_summer_fixing_the_bulldozer]->(:Object {name:\"d6 bulldozer\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_used_mail_order_to_buy_big_gears_for_the_bulldozers_transmission]->(:Object {name:\"big gears\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_built_a_crane_to_move_heavy_objects]->(:Object {name:\"crane\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_exhibited_a_strong_problem_solving_mentality]->(:Miscellanous {name:\"problem solving mentality\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:Lex_Fridmans_grandfather_did_his_own_veterinary_work]->(:Action {name:\"veterinary work\"}),\n",
    "                        (:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_fell_in_love_with_the_idea_of_space_exploration_at_the_age_of_five]->(:Miscellanous {name:\"space exploration\"}),\n",
    "                        (:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_was_inspired_by_watching_Neil_Armstrong_walking_on_the_moon]->(:Event {name:\"Neil Armstrong walking on the moon\"}),\n",
    "                        (:Event {name:\"space race from 1957 to 1969\"})-[:The_space_race_involved_the_Soviet_Union]->(:Place {name:\"Soviet Union\"}),\n",
    "                        (:Event {name:\"space race from 1957 to 1969\"})-[:The_space_race_involved_the_US]->(:Place {name:\"US\"})\n",
    "                    \"\"\"\n",
    "    EXAMPLE_RESULT = \"\"\"\n",
    "                        CREATE\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:BOUGHT {price: 'five thousand dollars'}]->(:Object {name:\"d6 bulldozer\"}),\n",
    "                        (:Object {name:\"d6 bulldozer\"})-[:DESCRIBED_AS]->(:Miscellanous {name:\"big bulldozer\"}),\n",
    "                        (:Object {name:\"d6 bulldozer\"})-[:SPECIFIC_TYPE]->(:Miscellanous {name:\"1955 caterpillar d6 bulldozer\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:FIXED {duration: 'entire summer'}]->(:Object {name:\"d6 bulldozer\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:ORDERED_PARTS {method: 'mail order'}]->(:Object {name:\"big gears\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:BUILT {objective: 'To move heavy objects'}]->(:Object {name:\"crane\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:EXHIBITED]->(:Miscellanous {name:\"problem solving mentality\"}),\n",
    "                        (:Person {name:\"Lex Fridman's grandfather\"})-[:PERFORMED]->(:Action {name:\"veterinary work\"}),\n",
    "                        (:Person {name:\"Jeff Bezos\"})-[:FELL_IN_LOVE_WITH {age: 'five'}]->(:Miscellanous {name:\"space exploration\"}),\n",
    "                        (:Person {name:\"Jeff Bezos\"})-[:INSPIRED_BY {event: 'Neil Armstrong walking on the moon'}]->(:Person {name:\"Neil Armstrong\"}),\n",
    "                        (:Event {name:\"space race from 1957 to 1969\"})-[:INVOLVED {country: 'Soviet Union'}]->(:Place {name:\"Soviet Union\"}),\n",
    "                        (:Event {name:\"space race from 1957 to 1969\"})-[:INVOLVED {country: 'US'}]->(:Place {name:\"US\"})\n",
    "                    \"\"\"\n",
    "\n",
    "    ontology = Ontology(\n",
    "        # labels of the entities to be extracted. Can be a string or an object, like the following.\n",
    "        labels=[\n",
    "            {\"Person\": \"Person name without any adjectives, Remember a person may be references by their name or using a pronoun\"},\n",
    "            {\"Object\": \"Do not add the definite article 'the' in the object name\"},\n",
    "            {\"Event\": \"Event event involving multiple people. Do include qualifiers or verbs like gives, leaves, works etc.\"},\n",
    "            \"Place\",\n",
    "            \"Document\",\n",
    "            \"Organisation\",\n",
    "            \"Action\",\n",
    "            {\"Miscellanous\": \"Any important concept can not be categorised with any other given label\"},\n",
    "        ],\n",
    "        # Relationships that are important for your application.\n",
    "        # These are more like instructions for the LLM to nudge it to focus on specific relationships.\n",
    "        # There is no guarentee that only these relationships will be extracted, but some models do a good job overall at sticking to these relations.\n",
    "        relationships=[\n",
    "            \"Relation between any pair of Entities\",\n",
    "            ],\n",
    "    )\n",
    "    model = \"gpt-4-turbo\"\n",
    "    llm = OpenAIClient(model=model, temperature=0.1, top_p=0.5)\n",
    "    graph_maker = GraphMaker(ontology=ontology, llm_client=llm, verbose=False)\n",
    "    net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "    @classmethod\n",
    "    def create_graph(cls, documents):\n",
    "        graph = cls.graph_maker.from_documents(\n",
    "            list(documents),\n",
    "            delay_s_between=10 ## delay_s_between because otherwise groq api maxes out pretty fast.\n",
    "            )\n",
    "        if graph:\n",
    "            print(\"Graph creatd with total number of Edges:\", len(graph))\n",
    "            return graph\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    # Function to check if a node exists\n",
    "    @classmethod\n",
    "    def node_exists(cls, net, node_id):\n",
    "        return any(node['id'] == node_id for node in net.nodes)\n",
    "\n",
    "    # Function to create a joined string\n",
    "    @classmethod\n",
    "    def create_joined_string(cls, input_string):\n",
    "        modified_string = input_string.replace(' ', '_')\n",
    "        modified_string = modified_string.replace(\"'\", \"\")\n",
    "        return modified_string\n",
    "\n",
    "    @classmethod\n",
    "    def build_graph_image(cls, graph):\n",
    "        for chunk in graph:\n",
    "            labels = [chunk.node_1.label, chunk.node_2.label]\n",
    "            ids = [chunk.node_1.name, chunk.node_2.name]\n",
    "            relationship = chunk.relationship\n",
    "            print(f\"{labels[0]}: {ids[0]} --> {labels[1]}:{ids[1]}; rel:{relationship}\")\n",
    "\n",
    "            for label,id in zip(labels,ids):\n",
    "                if not cls.node_exists(cls.net, node_id=id):\n",
    "                    cls.net.add_node(id, label=f\"{label}:{id}\")\n",
    "\n",
    "            cls.net.add_edge(ids[0], ids[1], title=relationship, arrows='to')\n",
    "\n",
    "    @classmethod\n",
    "    def save_graph_image(cls, filename):\n",
    "        cls.net.show_buttons(filter_=['physics'])\n",
    "        if filename.endswith('.html'):\n",
    "            cls.net.show(filename)\n",
    "        else:\n",
    "            print(\"Filename should have a .html extension\")\n",
    "        cls.net.show(filename)\n",
    "\n",
    "    @classmethod\n",
    "    def get_create_graph_query(cls, graph):\n",
    "        relationship_list = []\n",
    "        query = \"CREATE\\n\"\n",
    "        for chunk in graph:\n",
    "            labels = [chunk.node_1.label, chunk.node_2.label]\n",
    "            ids = [chunk.node_1.name, chunk.node_2.name]\n",
    "            relationship = cls.create_joined_string(chunk.relationship.split('.')[0])\n",
    "            relationship_list.append(relationship)\n",
    "            query += f\"\"\"(:{labels[0]} {{name:\"{ids[0]}\"}})-[:{relationship}]->(:{labels[1]} {{name:\"{ids[1]}\"}}),\\n\"\"\"\n",
    "        query =  query[:-2]\n",
    "        return query\n",
    "    \n",
    "    @classmethod\n",
    "    def clean_create_graph_query(cls, query):\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": cls.GRAPH_CLEANER_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": cls.EXAMPLE_PROMPT},\n",
    "            {\"role\": \"assistant\", \"content\": cls.EXAMPLE_RESULT},\n",
    "            {\"role\": \"user\", \"content\": f\"{query}\"},\n",
    "        ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    @classmethod\n",
    "    def check_missing_nodes(cls, query, text):\n",
    "        sys_prompt = f\"\"\"\n",
    "                    You are an expert at analysing cypher queries.\n",
    "                    You are provided with text and a cypher query. \n",
    "                    Your job is to determine if the cypher query is missing any nodes or relationships that are present in the text.\n",
    "                    Return the aspects that are missing. If nothing is missing, return 'none'.\n",
    "                    \"\"\"\n",
    "        user_prompt = f\"\"\"\n",
    "                    The text is:{text};\n",
    "                    The query is:{query};\n",
    "                    \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"system\", \"content\": user_prompt},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    @classmethod\n",
    "    def fix_missing_nodes(cls, query, text, missing):\n",
    "        sys_prompt = f\"\"\"\n",
    "                    You are an expert at analysing cypher queries.\n",
    "                    You are provided with text, a cypher query and what is missing in the cypher query.\n",
    "                    Your job is to add any missing nodes or relationships to the cypher query based on the text and return the modified query.\n",
    "                    Only add the missing nodes or relationships.\n",
    "                    Do not change the existing query in any way.\n",
    "                    \"\"\"\n",
    "        user_prompt = f\"\"\"\n",
    "                    The text is:{text};\n",
    "                    The query is:{query};\n",
    "                    Missing nodes/relationships are: {missing};\n",
    "                    \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo\",\n",
    "            temperature=0.0,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": sys_prompt},\n",
    "                {\"role\": \"system\", \"content\": user_prompt},\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    @classmethod\n",
    "    def run(cls, docs, graph_name):\n",
    "        # Connect to FalkorDB\n",
    "        db = FalkorDB(host='localhost', port=6379)\n",
    "        g = db.select_graph(graph_name)\n",
    "        graph = cls.create_graph(documents=docs)\n",
    "        #cls.build_graph_image(graph=graph)\n",
    "        #cls.save_graph_image(filename=\"graph.html\")\n",
    "        query = cls.get_create_graph_query(graph=graph)\n",
    "        print(\"FIRST CREATION QUERY:\",query)\n",
    "        modified_query = cls.clean_create_graph_query(query=query)\n",
    "        print(\"MODIFIED QUERY:\",modified_query)\n",
    "        #missing = cls.check_missing_nodes(modified_query, docs[0].text)\n",
    "        #print(\"MISSING NODES:\",missing)\n",
    "        #if missing.lower() != \"none\":\n",
    "        #    modified_query = cls.fix_missing_nodes(modified_query, docs[0].text, missing)\n",
    "        #    print(\"FIXED QUERY:\", modified_query)\n",
    "        g.query(modified_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrieveFromGraph:\n",
    "    def __init__(self, graph_name) -> None:\n",
    "        self.db = FalkorDB(host='localhost', port=6379)\n",
    "        self.graph = self.db.select_graph(graph_name)\n",
    "        self.QUESTION_GEN_PROMPT = \"\"\"\n",
    "        You’re a Cypher expert, with access to the following graph:\n",
    "        The knowledge graph schema is as follows:\n",
    "        The graph contains the following node labels:\n",
    "        {node_text}\n",
    "        the Module label has {node_length} number of nodes.\n",
    "        The graph contains the following relationship types:\n",
    "        {relationship_text}\n",
    "        This is the end of the knowledge graph schema description.\n",
    "        Ensure to generate the cypher query for the question passed to you\n",
    "        \"\"\"\n",
    "        self.question_prompt_template = PromptTemplate.from_template(self.QUESTION_GEN_PROMPT)\n",
    "\n",
    "    def create_query(self, question):\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": self.question_prompt_template.format(\n",
    "                node_text=self.view_nodes(), \n",
    "                node_length=self.get_total_number_of_nodes(), \n",
    "                relationship_text=self.view_edges())},\n",
    "            {\"role\": \"user\", \"content\": f\"{question}\"},\n",
    "        ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    def view_nodes(self):\n",
    "        node_text= \"\"\n",
    "        nodes = self.graph.query(\"\"\"MATCH (n) RETURN n\"\"\")\n",
    "        for node in nodes.result_set:\n",
    "            node_text += str(node[0]) + \"\\n\"\n",
    "        return (node_text)\n",
    "    \n",
    "    def get_total_number_of_nodes(self):\n",
    "        return len(self.graph.query(\"\"\"MATCH (n) RETURN n\"\"\").result_set)\n",
    "    \n",
    "    def get_unique_edge_set(self):\n",
    "        edge_set = set()\n",
    "        edges = self.graph.query(\"\"\"MATCH ()-[r]->() RETURN type(r) AS type, properties(r) AS properties\"\"\")\n",
    "        for e in edges.result_set:\n",
    "            temp_e = str(e[0])\n",
    "            for key, value in e[1].items():\n",
    "                temp_e += str(f\" {{{key}: {value}}}\")\n",
    "            edge_set.add(temp_e)\n",
    "        return edge_set\n",
    "    \n",
    "    def view_edges(self):\n",
    "        relationship_text = \"\"\n",
    "        edge_set = self.get_unique_edge_set()\n",
    "        for e in edge_set:\n",
    "            relationship_text += str(e)+ \"\\n\"\n",
    "        return (relationship_text)\n",
    "    \n",
    "    def get_cypher_text_from_output(self, text):\n",
    "        pattern = r'```cypher\\n(.*?)\\n```'\n",
    "        cypher_query = re.search(pattern, text, re.DOTALL)\n",
    "        return cypher_query.group(1)\n",
    "    \n",
    "    def get_total_number_of_edges(self):\n",
    "        edge_set = self.get_unique_edge_set()\n",
    "        edge_len=len(edge_set)\n",
    "        return edge_len\n",
    "\n",
    "    def get_answer(self, question):\n",
    "        query = self.create_query(question)\n",
    "        print(\"QUERY:\",query)\n",
    "        cypher_query = self.get_cypher_text_from_output(query)\n",
    "        answer=self.graph.query(cypher_query)\n",
    "        return answer.result_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToCypher:\n",
    "    TRIPLET_PROMPT = \"\"\"\n",
    "                    You are an expert at creating graphs from text using OpenCypher.\n",
    "                    You are provided with a text and your job is to create a graph from the text.\n",
    "                    Ensure to create the graph based on the relationships between the entities in the text.\n",
    "                    Ensure too set nouns as nodes and verbs as relationships.\n",
    "\n",
    "                    ## Ensure to not use metadata unless necessary and ensure to normalize the relationships between the nodes.:\n",
    "                    For example:\n",
    "                    Incorrect:\n",
    "                    ```\n",
    "                    MERGE (p1:Person { name: \"David\", interest: [\"Guitar\"] })\n",
    "                    MERGE (p2:Person { name: \"Sarah\", interest: [\"Guitar\"] })\n",
    "                    ```\n",
    "                    Correct(normalised relationships):\n",
    "                    ```\n",
    "                    MERGE (s:Interest { name: \"Guitar\" })\n",
    "                    MERGE (p1:Person { name: \"David\" })\n",
    "                    MERGE (p1)-[:HAS]->(s)\n",
    "                    MERGE (p2:Person { name: \"Sarah\" })\n",
    "                    MERGE (p2)-[:HAS]->(s)\n",
    "                    ```\n",
    "\n",
    "                    ##Ensure to capture possessive relationships as well:\n",
    "                    John's car is red: should generate a node for John and a node for car with property color as red.\n",
    "                    \n",
    "                    ##Ensure to not be ambiguous in the relationships between the nodes:\n",
    "                    Ensure to capture the relationships between the nodes with enough detail to not be ambiguous.\n",
    "\n",
    "                    ##Ensure to Reify the relationships between the nodes:\n",
    "                    To reify a relationship is to make it an entity in its own right. \n",
    "                    For example, if you have a relationship between a person and a car, \n",
    "                    you can reify that relationship into a new entity called \"owns\" and connect the person and the car to the \"owns\" entity.\n",
    "\n",
    "                    ##Capture all details in the text within the graph:\n",
    "                    \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def cypher_from_text_first_pass(cls, text):\n",
    "        #TODO: entire text is dumped for the time being, need to split it into chunks if it exceeds the limit\n",
    "        USER_PROMPT = \"\"\"\n",
    "                    The text is:\n",
    "                    {text} \n",
    "                    Try to not use any metadata unless necessary and ensure to normalize the relationships between the nodes.\n",
    "                    Ensure the relationships between the nodes are not ambiguous and capture all details in the text within the graph and make sense.\n",
    "                    \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": cls.TRIPLET_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(text=text)},\n",
    "        ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "    @classmethod\n",
    "    def get_cypher_text_from_result(cls, text):\n",
    "        pattern = r'```cypher\\n(.*?)\\n```'\n",
    "        cypher_query = re.search(pattern, text, re.DOTALL)\n",
    "        return cypher_query.group(1)\n",
    "\n",
    "    @classmethod\n",
    "    def cypher_from_text_second_pass(cls, text, cypher):\n",
    "        USER_PROMPT = \"\"\"\n",
    "                        The text is: {text}. The cypher query is: {cypher}, modify the cypher query to even include implicit relationships between the nodes. \n",
    "                        Do not add in any nodes or relationships that are not present in the text. Ensure to capture all relationships between the nodes in the text.\n",
    "                    \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",\n",
    "        temperature=0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": cls.TRIPLET_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": USER_PROMPT.format(text=text, cypher=cypher)},\n",
    "        ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    \n",
    "    @classmethod\n",
    "    def run(cls, text):\n",
    "        first_pass = cls.cypher_from_text_first_pass(text)\n",
    "        first_cypher = cls.get_cypher_text_from_result(first_pass)\n",
    "        second_pass = cls.cypher_from_text_second_pass(text, first_cypher)\n",
    "        second_cypher = cls.get_cypher_text_from_result(second_pass)\n",
    "        #print(\"first cypher:\", first_cypher)\n",
    "        #print(\"second cypher:\", second_cypher)\n",
    "        return second_cypher\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing graph\n",
    "graph_name = \"Conv1\"\n",
    "db = FalkorDB(host='localhost', port=6379)\n",
    "g = db.select_graph(graph_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "doc = ProcessConversation.create_docs(infile_file_path=\"./docs/bezos.txt\", \n",
    "                                    speaker_mapping={\"SPEAKER_00\": \"Jeff Bezos\", \"SPEAKER_01\": \"Lex Fridman\"})\n",
    "\"\"\"\n",
    "doc = [\n",
    "       Document(text=\"The following is a conversation with Jeff Bezos, founder of Amazon and Blue Origin. This is Jeff Bezos's first time doing a conversation of this kind and of this length. And as Jeff Bezos told Lex Fridman, it felt like Lex Fridman and Jeff Bezos could have easily talked for many more hours, and Lex Fridman is sure Lex Fridman and Jeff Bezos will.\", metadata={'num': '1'}),\n",
    "       Document(text=\"This is the Lex Friedman Podcast. And now, dear friends, here's Jeff Bezos. Jeff Bezos spent a lot of Jeff Bezos's childhood with Jeff Bezos's grandfather on a ranch here in Texas.\", metadata={'num': '2'}),\n",
    "       Document(text=\"And Lex Fridman heard Jeff Bezos had a lot of work to do around the ranch. So what's the coolest job Jeff Bezos remembers doing there? Wow, coolest.\", metadata={'num': '3'}),\n",
    "       Document(text=\"Most interesting. Most memorable. Most memorable.\", metadata={'num': '4'}),\n",
    "       Document(text=\"Most impactful. It's a real working ranch. And Jeff Bezos spent all Jeff Bezos's summers on that ranch from age four to 16. And Jeff Bezos's grandfather was really taking Jeff Bezos in the summers and the In the early summers, Jeff Bezos's grandfather was letting Jeff Bezos pretend to help on the ranch because, of course, a four-year-old is a burden, not a help in real life.\", metadata={'num': '5'}),\n",
    "       Document(text=\"Jeff Bezos's grandfather was really just watching Jeff Bezos and taking care of Jeff Bezos. Jeff Bezos's grandfather was doing that because Jeff Bezos's mom was so young. She had Jeff Bezos when she was 17, and so Jeff Bezos's grandfather was sort of giving her a break, and Jeff Bezos's grandmother and Jeff Bezos's grandfather would take Jeff Bezos for the summers.\", metadata={'num': '6'})\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a conversation with Jeff Bezos, founder of Amazon and Blue Origin. This is Jeff Bezos's first time doing a conversation of this kind and of this length. And as Jeff Bezos told Lex Fridman, it felt like Lex Fridman and Jeff Bezos could have easily talked for many more hours, and Lex Fridman is sure Lex Fridman and Jeff Bezos will.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "text = doc[i].text\n",
    "print(text)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "// Create nodes for the people and organizations\n",
      "MERGE (jeff:Person {name: \"Jeff Bezos\"})\n",
      "MERGE (lex:Person {name: \"Lex Fridman\"})\n",
      "MERGE (amazon:Company {name: \"Amazon\"})\n",
      "MERGE (blueOrigin:Company {name: \"Blue Origin\"})\n",
      "\n",
      "// Create relationships for founding\n",
      "MERGE (jeff)-[:FOUNDED]->(amazon)\n",
      "MERGE (jeff)-[:FOUNDED]->(blueOrigin)\n",
      "\n",
      "// Create a node for the conversation event\n",
      "MERGE (conversation:Conversation {type: \"First long conversation\"})\n",
      "\n",
      "// Connect Jeff and Lex to the conversation\n",
      "MERGE (jeff)-[:PARTICIPATED_IN]->(conversation)\n",
      "MERGE (lex)-[:PARTICIPATED_IN]->(conversation)\n",
      "\n",
      "// Express the potential for future conversations\n",
      "MERGE (futureConversations:FutureConversations {description: \"Potential for many more hours of conversation\"})\n",
      "\n",
      "// Connect Jeff and Lex to future conversations\n",
      "MERGE (jeff)-[:MAY_HAVE]->(futureConversations)\n",
      "MERGE (lex)-[:MAY_HAVE]->(futureConversations)\n",
      "\n",
      "// Reify the relationship of telling\n",
      "MERGE (telling:Event {description: \"Jeff Bezos told Lex Fridman\"})\n",
      "MERGE (jeff)-[:TOLD]->(telling)\n",
      "MERGE (telling)-[:TO]->(lex)\n",
      "\n",
      "// Connect the telling event to the conversation\n",
      "MERGE (telling)-[:DURING]->(conversation)\n",
      "\n",
      "// Reify the relationship of assurance\n",
      "MERGE (assurance:Event {description: \"Lex Fridman is sure they will talk more\"})\n",
      "MERGE (lex)-[:EXPRESSED]->(assurance)\n",
      "MERGE (assurance)-[:ABOUT]->(futureConversations)\n",
      "\n",
      "// Connect the assurance to the conversation\n",
      "MERGE (assurance)-[:DURING]->(conversation)\n"
     ]
    }
   ],
   "source": [
    "cypher = TextToCypher.run(text) \n",
    "print(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_cypher_to_json(cypher):\n",
    "    # Define regex patterns to match nodes and relationships\n",
    "    node_pattern = r'MERGE \\((\\w+):(\\w+) {([^}]+)}\\)'\n",
    "    relationship_pattern = r'MERGE \\((\\w+)\\)-\\[:(\\w+)\\]->\\((\\w+)\\)'\n",
    "    \n",
    "    nodes = {}\n",
    "    relationships = []\n",
    "    \n",
    "    # Extract nodes\n",
    "    for match in re.finditer(node_pattern, cypher):\n",
    "        var, label, attrs = match.groups()\n",
    "        attr_dict = {}\n",
    "        for attr in attrs.split(\", \"):\n",
    "            key, value = attr.split(\": \")\n",
    "            attr_dict[key] = value.strip('\"')\n",
    "        name = attr_dict.get('name', attr_dict.get('kind', 'Unknown'))\n",
    "        nodes[var] = {\"label\": label, \"name\": name}\n",
    "    \n",
    "    # Extract relationships\n",
    "    for match in re.finditer(relationship_pattern, cypher):\n",
    "        node_1, rel, node_2 = match.groups()\n",
    "        relationships.append({\n",
    "            \"node_1\": nodes[node_1],\n",
    "            \"node_2\": nodes[node_2],\n",
    "            \"relationship\": f\"{nodes[node_1]['name']} {rel.lower().replace('_', ' ')} {nodes[node_2]['name']}\"\n",
    "        })\n",
    "    \n",
    "    return json.dumps(relationships, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Jeff Bezos\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Company\",\n",
      "            \"name\": \"Amazon\"\n",
      "        },\n",
      "        \"relationship\": \"Jeff Bezos founded Amazon\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Jeff Bezos\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Company\",\n",
      "            \"name\": \"Blue Origin\"\n",
      "        },\n",
      "        \"relationship\": \"Jeff Bezos founded Blue Origin\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Jeff Bezos\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Conversation\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Jeff Bezos participated in Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Lex Fridman\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Conversation\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Lex Fridman participated in Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Jeff Bezos\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"FutureConversations\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Jeff Bezos may have Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Lex Fridman\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"FutureConversations\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Lex Fridman may have Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Jeff Bezos\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Event\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Jeff Bezos told Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Event\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Lex Fridman\"\n",
      "        },\n",
      "        \"relationship\": \"Unknown to Lex Fridman\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Event\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Conversation\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Unknown during Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Person\",\n",
      "            \"name\": \"Lex Fridman\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Event\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Lex Fridman expressed Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Event\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"FutureConversations\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Unknown about Unknown\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\n",
      "            \"label\": \"Event\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"node_2\": {\n",
      "            \"label\": \"Conversation\",\n",
      "            \"name\": \"Unknown\"\n",
      "        },\n",
      "        \"relationship\": \"Unknown during Unknown\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "f = parse_cypher_to_json(cypher)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationships_and_nodes_with_properties(cypher_str):\n",
    "    # Regular expression patterns to match the CREATE statements with relationships and properties\n",
    "    node_pattern = re.compile(r'\\((\\w+):(\\w+)(?: \\{([^\\}]*)\\})?\\)')\n",
    "    relationship_pattern = re.compile(r'MERGE \\((\\w+)\\)-\\[:(\\w+)\\]->\\((\\w+)\\)')\n",
    "\n",
    "    # Function to parse properties string to a dictionary\n",
    "    def parse_properties(properties_str):\n",
    "        if not properties_str:\n",
    "            return {}\n",
    "        properties = properties_str.split(', ')\n",
    "        prop_dict = {}\n",
    "        for prop in properties:\n",
    "            key, value = prop.split(': ')\n",
    "            # Remove quotes from string values\n",
    "            value = value.strip('\"')\n",
    "            prop_dict[key] = value\n",
    "        return prop_dict\n",
    "\n",
    "    nodes = {}\n",
    "    relationships = {}\n",
    "\n",
    "    # Extract nodes and their properties\n",
    "    for match in node_pattern.finditer(cypher_str):\n",
    "        node_var, label, properties_str = match.groups()\n",
    "        properties = parse_properties(properties_str)\n",
    "        nodes[node_var] = {\"label\": label, \"properties\": properties}\n",
    "\n",
    "    # Extract relationships and associate nodes\n",
    "    for match in relationship_pattern.finditer(cypher_str):\n",
    "        node1, rel_type, node2 = match.groups()\n",
    "        if rel_type not in relationships:\n",
    "            relationships[rel_type] = []\n",
    "        relationships[rel_type].append({\n",
    "            \"node_1\": nodes[node1],\n",
    "            \"node_2\": nodes[node2]\n",
    "        })\n",
    "\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FOUNDED': [{'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Organization', 'properties': {'name': 'Amazon'}}}, {'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Organization', 'properties': {'name': 'Blue Origin'}}}], 'PARTICIPATED_IN': [{'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Conversation', 'properties': {'kind': 'first time', 'length': 'long'}}}, {'node_1': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}, 'node_2': {'label': 'Conversation', 'properties': {'kind': 'first time', 'length': 'long'}}}], 'TOLD': [{'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}}], 'COULD_HAVE_TALKED_FOR_MORE_HOURS_WITH': [{'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}}], 'SURE_THAT_WILL_TALK_AGAIN_WITH': [{'node_1': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}}], 'IS_ASSOCIATED_WITH': [{'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Organization', 'properties': {'name': 'Amazon'}}}, {'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Organization', 'properties': {'name': 'Blue Origin'}}}, {'node_1': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}, 'node_2': {'label': 'Conversation', 'properties': {'kind': 'first time', 'length': 'long'}}}], 'HAS_A_CONVERSATION': [{'node_1': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}}, {'node_1': {'label': 'Person', 'properties': {'name': 'Lex Fridman'}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}}]}\n"
     ]
    }
   ],
   "source": [
    "rel_dict = extract_relationships_and_nodes_with_properties(cypher)\n",
    "print(rel_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first cypher: // Create nodes\n",
      "MERGE (podcast:Podcast {name: \"Lex Friedman Podcast\"})\n",
      "MERGE (jeff:Person {name: \"Jeff Bezos\"})\n",
      "MERGE (grandfather:Person {name: \"Grandfather\"}) // Assuming the name is not specified\n",
      "MERGE (ranch:Location {name: \"Ranch\", state: \"Texas\"})\n",
      "MERGE (childhood:Period {name: \"Childhood\"})\n",
      "\n",
      "// Create relationships\n",
      "MERGE (jeff)-[:GUEST_ON]->(podcast)\n",
      "MERGE (childhood)-[:SPENT_WITH]->(grandfather)\n",
      "MERGE (childhood)-[:OCCURRED_AT]->(ranch)\n",
      "MERGE (jeff)-[:HAD]->(childhood)\n",
      "second cypher: // Create nodes\n",
      "MERGE (podcast:podcast {name: \"Lex Friedman Podcast\"})\n",
      "MERGE (jeff:person {name: \"Jeff Bezos\"})\n",
      "MERGE (grandfather:person {name: \"Grandfather\"}) // Assuming the name is not specified\n",
      "MERGE (ranch:location {name: \"Ranch\", state: \"Texas\"})\n",
      "MERGE (childhood:period {name: \"Childhood\"})\n",
      "\n",
      "// Create relationships\n",
      "MERGE (jeff)-[:GUEST_ON]->(podcast)\n",
      "MERGE (jeff)-[:SPENT]->(childhood)\n",
      "MERGE (childhood)-[:WITH]->(grandfather)\n",
      "MERGE (childhood)-[:AT]->(ranch)\n",
      "MERGE (jeff)-[:HAD]->(childhood)\n"
     ]
    }
   ],
   "source": [
    "g.query(cypher)\n",
    "nodes = g.query(\"\"\"MATCH (n) RETURN n\"\"\")\n",
    "for node in nodes.result_set:\n",
    "    print(node[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<falkordb.query_result.QueryResult at 0x782ca956bb10>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g.query(cypher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(:person{name:\"Jeff Bezos\"})\n",
      "(:person{name:\"Lex Fridman\"})\n",
      "(:company{name:\"Amazon\"})\n",
      "(:company{name:\"Blue Origin\"})\n",
      "(:conversation{firstTime:True,length:\"long\",type:\"Interview\"})\n",
      "(:futureConversations{description:\"Potential continuation\"})\n",
      "(:podcast{name:\"Lex Friedman Podcast\"})\n",
      "(:person{name:\"Grandfather\"})\n",
      "(:location{name:\"Ranch\",state:\"Texas\"})\n",
      "(:period{name:\"Childhood\"})\n"
     ]
    }
   ],
   "source": [
    "nodes = g.query(\"\"\"MATCH (n) RETURN n\"\"\")\n",
    "for node in nodes.result_set:\n",
    "    print(node[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(notebook=True, cdn_resources='in_line')\n",
    "\n",
    "def node_exists(net, node_id):\n",
    "    return any(node['id'] == node_id for node in net.nodes)\n",
    "\n",
    "def save_graph_image(filename):\n",
    "    net.show_buttons(filter_=['physics'])\n",
    "    if filename.endswith('.html'):\n",
    "        net.show(filename)\n",
    "    else:\n",
    "        print(\"Filename should have a .html extension\")\n",
    "    net.show(filename)\n",
    "\n",
    "def create_graph_image(graph, filename):\n",
    "    for chunk in graph:\n",
    "        labels = [chunk.node_1.label, chunk.node_2.label]\n",
    "        ids = [chunk.node_1.name, chunk.node_2.name]\n",
    "        relationship = chunk.relationship\n",
    "        print(f\"{labels[0]}: {ids[0]} --> {labels[1]}:{ids[1]}; rel:{relationship}\")\n",
    "\n",
    "        for label,id in zip(labels,ids):\n",
    "            if not node_exists(net, node_id=id):\n",
    "                net.add_node(id, label=f\"{label}:{id}\")\n",
    "\n",
    "        net.add_edge(ids[0], ids[1], title=relationship, arrows='to')\n",
    "\n",
    "    save_graph_image(filename)\n",
    "\n",
    "\n",
    "def extract_relationships_and_nodes_with_properties(cypher_str):\n",
    "    # Regular expression patterns to match the CREATE statements with relationships and properties\n",
    "    node_pattern = re.compile(r'\\((\\w+):(\\w+)(?: \\{([^\\}]*)\\})?\\)')\n",
    "    relationship_pattern = re.compile(r'CREATE \\((\\w+)\\)-\\[:(\\w+)\\]->\\((\\w+)\\)')\n",
    "\n",
    "    # Function to parse properties string to a dictionary\n",
    "    def parse_properties(properties_str):\n",
    "        if not properties_str:\n",
    "            return {}\n",
    "        properties = properties_str.split(', ')\n",
    "        prop_dict = {}\n",
    "        for prop in properties:\n",
    "            key, value = prop.split(': ')\n",
    "            # Remove quotes from string values\n",
    "            value = value.strip('\"')\n",
    "            prop_dict[key] = value\n",
    "        return prop_dict\n",
    "\n",
    "    nodes = {}\n",
    "    relationships = {}\n",
    "\n",
    "    # Extract nodes and their properties\n",
    "    for match in node_pattern.finditer(cypher_str):\n",
    "        node_var, label, properties_str = match.groups()\n",
    "        properties = parse_properties(properties_str)\n",
    "        nodes[node_var] = {\"label\": label, \"properties\": properties}\n",
    "\n",
    "    # Extract relationships and associate nodes\n",
    "    for match in relationship_pattern.finditer(cypher_str):\n",
    "        node1, rel_type, node2 = match.groups()\n",
    "        if rel_type not in relationships:\n",
    "            relationships[rel_type] = []\n",
    "        relationships[rel_type].append({\n",
    "            \"node_1\": nodes[node1],\n",
    "            \"node_2\": nodes[node2]\n",
    "        })\n",
    "\n",
    "    return relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TOOK_CARE_OF_JB_DURING_SUMMERS': [{'node_1': {'label': 'Person', 'properties': {'name': \"Jeff Bezos's Grandfather\"}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}}], 'INVOLVED': [{'node_1': {'label': 'Activity', 'properties': {'description': 'pretend to help on the ranch'}}, 'node_2': {'label': 'Person', 'properties': {'name': 'Jeff Bezos'}}}]}\n"
     ]
    }
   ],
   "source": [
    "rel = extract_relationships_and_nodes_with_properties(cyp_text_2)\n",
    "print(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Graph' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcreate_graph_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgraph.html\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 15\u001b[0m, in \u001b[0;36mcreate_graph_image\u001b[0;34m(graph, filename)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_graph_image\u001b[39m(graph, filename):\n\u001b[0;32m---> 15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mids\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Graph' object is not iterable"
     ]
    }
   ],
   "source": [
    "create_graph_image(g, \"graph.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgraph\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING NODES: The provided cypher query captures several aspects of Jeff Bezos's life and interactions, including his founding of Amazon and Blue Origin, his conversation with Lex Fridman, and some details about his family and childhood. However, upon reviewing the text, it appears that the query does not include all the relevant information:\n",
      "\n",
      "1. **Missing Relationship Details in Conversation**: The query mentions the conversation between Jeff Bezos and Lex Fridman, including some details about the conversation's nature and mutual feelings. However, it does not explicitly state that this was Jeff Bezos's first time doing a conversation of this kind and length, which is a significant aspect of the conversation's uniqueness.\n",
      "\n",
      "2. **Missing Details about Lex Fridman's Assurance**: While the query mentions mutual assurance in the conversation, it specifically highlights that \"Lex Fridman is sure Lex Fridman and Jeff Bezos will\" talk again. This assurance from Lex Fridman's perspective is not captured as a separate or emphasized detail in the relationship attributes.\n",
      "\n",
      "3. **Missing Personal Details**: The query includes detailed personal history about Jeff Bezos's childhood and family but does not mention anything about Lex Fridman's background or personal details, which might not be necessary given the text but is worth noting if comprehensive relational mapping is the goal.\n",
      "\n",
      "Given these observations, the missing aspects in the query relative to the text are:\n",
      "- Explicit mention of the conversation being Jeff Bezos's first of this kind and length.\n",
      "- Emphasized detail of Lex Fridman's assurance about future conversations.\n",
      "\n",
      "If these aspects are considered necessary for the completeness of the query based on the text, they should be added. Otherwise, the query covers the major points shared in the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIXED QUERY: CREATE\n",
      "(:Person {name:\"Jeff Bezos\"})-[:FOUNDED]->(:Organisation {name:\"Amazon\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:FOUNDED]->(:Organisation {name:\"Blue Origin\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:HAD_CONVERSATION_WITH {details: \"could have talked for many more hours, will talk again\", first_time: \"true\", feeling: \"felt like\", first_of_kind_and_length: \"true\"}]->(:Person {name:\"Lex Fridman\"}),\n",
      "(:Person {name:\"Lex Fridman\"})-[:HAD_CONVERSATION_WITH {details: \"could have talked for many more hours, will talk again\", mutual_assurance: \"true\", assured_future_conversation: \"true\"}]->(:Person {name:\"Jeff Bezos\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:SPENT_CHILDHOOD_IN {location: \"ranch\", details: \"spent a lot of time, did a lot of work, remembers doing the coolest job\"}]->(:Place {name:\"Texas\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:SPENT_SUMMERS_WITH {age_range: \"from age four to 16\"}]->(:Person {name:\"Jeff Bezos's grandfather\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:GRANDFATHER {relationship: \"took care during summers, watched over, gave breaks to mom\"}]->(:Person {name:\"Jeff Bezos's grandfather\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandfather\"})-[:TOOK_CARE_WITH]->(:Person {name:\"grandmother\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:BORN_TO {age_of_mother: \"17\"}]->(:Person {name:\"mom\"});\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "CREATE\n",
    "(:Person {name:\"Jeff Bezos\"})-[:FOUNDED]->(:Organisation {name:\"Amazon\"}),\n",
    "(:Person {name:\"Jeff Bezos\"})-[:FOUNDED]->(:Organisation {name:\"Blue Origin\"}),\n",
    "(:Person {name:\"Jeff Bezos\"})-[:HAD_CONVERSATION_WITH {details: \"could have talked for many more hours, will talk again\", first_time: \"true\", feeling: \"felt like\"}]->(:Person {name:\"Lex Fridman\"}),\n",
    "(:Person {name:\"Lex Fridman\"})-[:HAD_CONVERSATION_WITH {details: \"could have talked for many more hours, will talk again\", mutual_assurance: \"true\"}]->(:Person {name:\"Jeff Bezos\"}),\n",
    "(:Person {name:\"Jeff Bezos\"})-[:SPENT_CHILDHOOD_IN {location: \"ranch\", details: \"spent a lot of time, did a lot of work, remembers doing the coolest job\"}]->(:Place {name:\"Texas\"}),\n",
    "(:Person {name:\"Jeff Bezos\"})-[:SPENT_SUMMERS_WITH {age_range: \"from age four to 16\"}]->(:Person {name:\"Jeff Bezos's grandfather\"}),\n",
    "(:Person {name:\"Jeff Bezos\"})-[:GRANDFATHER {relationship: \"took care during summers, watched over, gave breaks to mom\"}]->(:Person {name:\"Jeff Bezos's grandfather\"}),\n",
    "(:Person {name:\"Jeff Bezos's grandfather\"})-[:TOOK_CARE_WITH]->(:Person {name:\"grandmother\"}),\n",
    "(:Person {name:\"Jeff Bezos\"})-[:BORN_TO {age_of_mother: \"17\"}]->(:Person {name:\"mom\"});\n",
    "\"\"\"\n",
    "missing = CreateGraph.check_missing_nodes(query, doc[0].text)\n",
    "print(\"MISSING NODES:\",missing)\n",
    "\n",
    "if missing.lower() != \"none\":\n",
    "    modified_query = CreateGraph.fix_missing_nodes(query, doc[0].text, missing)\n",
    "    print(\"FIXED QUERY:\", modified_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[39m\n",
      "\u001b[92m▶︎ GRAPH MAKER LOG - 2024-06-02 18:19:03 - INFO \u001b[39m\n",
      "\u001b[92mDocument: 1\u001b[39m\n",
      "\u001b[92m\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Model:  gpt-4-turbo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[92m\u001b[39m\n",
      "\u001b[92m▶︎ GRAPH MAKER LOG - 2024-06-02 18:19:23 - INFO \u001b[39m\n",
      "\u001b[92mTrying JSON Parsing: \n",
      "[\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"node_2\": {\"label\": \"Organisation\", \"name\": \"Amazon\"},\n",
      "        \"relationship\": \"Jeff Bezos is the founder of Amazon.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"node_2\": {\"label\": \"Organisation\", \"name\": \"Blue Origin\"},\n",
      "        \"relationship\": \"Jeff Bezos is the founder of Blue Origin.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"node_2\": {\"label\": \"Person\", \"name\": \"Lex Fridman\"},\n",
      "        \"relationship\": \"Jeff Bezos had a conversation with Lex Fridman.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Lex Fridman\"},\n",
      "        \"node_2\": {\"label\": \"Document\", \"name\": \"Lex Friedman Podcast\"},\n",
      "        \"relationship\": \"Lex Fridman hosts the Lex Friedman Podcast.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"node_2\": {\"label\": \"Place\", \"name\": \"Texas\"},\n",
      "        \"relationship\": \"Jeff Bezos spent a lot of his childhood with his grandfather on a ranch in Texas.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"node_2\": {\"label\": \"Person\", \"name\": \"Jeff Bezos's grandfather\"},\n",
      "        \"relationship\": \"Jeff Bezos spent his summers from age four to 16 on a ranch under the care of his grandfather.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos's grandfather\"},\n",
      "        \"node_2\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"relationship\": \"Jeff Bezos's grandfather took care of him during the summers, allowing him to pretend to help on the ranch.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos's mom\"},\n",
      "        \"node_2\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"relationship\": \"Jeff Bezos's mom had Jeff Bezos when she was 17.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos's grandfather\"},\n",
      "        \"node_2\": {\"label\": \"Person\", \"name\": \"Jeff Bezos's mom\"},\n",
      "        \"relationship\": \"Jeff Bezos's grandfather was giving her a break by taking care of Jeff Bezos during the summers.\"\n",
      "    },\n",
      "    {\n",
      "        \"node_1\": {\"label\": \"Person\", \"name\": \"Jeff Bezos's grandmother\"},\n",
      "        \"node_2\": {\"label\": \"Person\", \"name\": \"Jeff Bezos\"},\n",
      "        \"relationship\": \"Jeff Bezos's grandmother, along with his grandfather, would take Jeff Bezos for the summers.\"\n",
      "    }\n",
      "]\u001b[39m\n",
      "\u001b[92m\u001b[39m\n",
      "\u001b[92m\u001b[39m\n",
      "\u001b[92m▶︎ GRAPH MAKER LOG - 2024-06-02 18:19:23 - INFO \u001b[39m\n",
      "\u001b[92mJSON Parsing Successful!\u001b[39m\n",
      "\u001b[92m\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph creatd with total number of Edges: 10\n",
      "FIRST CREATION QUERY: CREATE\n",
      "(:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_is_the_founder_of_Amazon]->(:Organisation {name:\"Amazon\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_is_the_founder_of_Blue_Origin]->(:Organisation {name:\"Blue Origin\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_had_a_conversation_with_Lex_Fridman]->(:Person {name:\"Lex Fridman\"}),\n",
      "(:Person {name:\"Lex Fridman\"})-[:Lex_Fridman_hosts_the_Lex_Friedman_Podcast]->(:Document {name:\"Lex Friedman Podcast\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_spent_a_lot_of_his_childhood_with_his_grandfather_on_a_ranch_in_Texas]->(:Place {name:\"Texas\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:Jeff_Bezos_spent_his_summers_from_age_four_to_16_on_a_ranch_under_the_care_of_his_grandfather]->(:Person {name:\"Jeff Bezos's grandfather\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandfather\"})-[:Jeff_Bezoss_grandfather_took_care_of_him_during_the_summers,_allowing_him_to_pretend_to_help_on_the_ranch]->(:Person {name:\"Jeff Bezos\"}),\n",
      "(:Person {name:\"Jeff Bezos's mom\"})-[:Jeff_Bezoss_mom_had_Jeff_Bezos_when_she_was_17]->(:Person {name:\"Jeff Bezos\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandfather\"})-[:Jeff_Bezoss_grandfather_was_giving_her_a_break_by_taking_care_of_Jeff_Bezos_during_the_summers]->(:Person {name:\"Jeff Bezos's mom\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandmother\"})-[:Jeff_Bezoss_grandmother,_along_with_his_grandfather,_would_take_Jeff_Bezos_for_the_summers]->(:Person {name:\"Jeff Bezos\"})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODIFIED QUERY: CREATE\n",
      "(:Person {name:\"Jeff Bezos\"})-[:FOUNDER_OF]->(:Organisation {name:\"Amazon\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:FOUNDER_OF]->(:Organisation {name:\"Blue Origin\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:HAD_CONVERSATION_WITH]->(:Person {name:\"Lex Fridman\"}),\n",
      "(:Person {name:\"Lex Fridman\"})-[:HOSTS]->(:Document {name:\"Lex Friedman Podcast\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:SPENT_CHILDHOOD_AT {location: 'ranch', state: 'Texas'}]->(:Place {name:\"Texas\"}),\n",
      "(:Person {name:\"Jeff Bezos\"})-[:CARED_FOR_BY {age_range: 'four to 16', during: 'summers'}]->(:Person {name:\"Jeff Bezos's grandfather\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandfather\"})-[:CARED_FOR {activity: 'pretend help on ranch', during: 'summers'}]->(:Person {name:\"Jeff Bezos\"}),\n",
      "(:Person {name:\"Jeff Bezos's mom\"})-[:HAD_AT_AGE {age: '17'}]->(:Person {name:\"Jeff Bezos\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandfather\"})-[:GAVE_BREAK_TO {during: 'summers'}]->(:Person {name:\"Jeff Bezos's mom\"}),\n",
      "(:Person {name:\"Jeff Bezos's grandmother\"})-[:TOOK_FOR_SUMMERS]->(:Person {name:\"Jeff Bezos\"})\n"
     ]
    }
   ],
   "source": [
    "graph = CreateGraph.run(docs=doc, graph_name=\"Convo-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_to_query = RetrieveFromGraph(graph_name=\"Convo-1\")\n",
    "nodes  = graph_to_query.view_nodes()\n",
    "edges = graph_to_query.view_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUERY: To find out the age range during which Jeff Bezos's grandfather took care of him, we can use the relationship type `CARED_FOR_BY` which includes an age range attribute. Here's the Cypher query to retrieve this information:\n",
      "\n",
      "```cypher\n",
      "MATCH (p:Person {name: \"Jeff Bezos\"})-[r:CARED_FOR_BY]->(g:Person {name: \"Jeff Bezos's grandfather\"})\n",
      "RETURN r.age_range AS AgeRange\n",
      "```\n",
      "\n",
      "This query matches the nodes representing Jeff Bezos and his grandfather connected by the `CARED_FOR_BY` relationship and returns the age range during which his grandfather took care of him.\n",
      "['four to 16']\n"
     ]
    }
   ],
   "source": [
    "question = \"How old was Jeff Bezos when his grandfather took care of him?\"\n",
    "ans = graph_to_query.get_answer(question)\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
